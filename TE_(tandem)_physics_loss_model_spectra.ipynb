{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8oij1RQg0n_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWv5_4BRmUFo"
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import csv\n",
        "import sys\n",
        "import datetime\n",
        "import pywt\n",
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.fftpack import fft\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, BatchNormalization\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from scipy.stats import itemfreq\n",
        "import os\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "from numpy import pi, linspace, inf, array\n",
        "from scipy.interpolate import interp1d\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDfxjqnCmK47",
        "outputId": "dd53f7c5-ec04-4e35-e951-52431adad36b"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czcYR3-3mPbp",
        "outputId": "64e2def8-f5ba-4bd7-c10d-0c4125f2c94b"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLWGFoKMmRa5",
        "outputId": "b13a3385-145d-46e0-cf9a-6bde7986ea16"
      },
      "source": [
        "torch.cuda.device_count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHSm4-dPFZbi",
        "outputId": "82d8cdac-28d8-4914-d86c-b9bae2abba6d"
      },
      "source": [
        "\n",
        "\n",
        "posttraimodel = pd.read_excel('/content/drive/My Drive/Files/TE/train-inverse-all-spectra.xlsx')\n",
        "\n",
        "#test = pd.read_excel('/content/drive/My Drive/Files/TM/test-autoencoder-wpt1t2-500-700nm(eps-std)(non spectra).xlsx')\n",
        "test = pd.read_excel('/content/drive/My Drive/Files/TE/test-inverse-all-spectra.xlsx')\n",
        "\n",
        "print(posttraimodel.shape, test.shape)\n",
        "\n",
        "forward_model = torch.load('/content/drive/My Drive/Files/TE/forward model/pt2gapt-spectra-reduced arch-all design-1.pt')\n",
        "\n",
        "\n",
        "x_inverse = np.array(posttraimodel)[:,4:]\n",
        "\n",
        "x_test = np.array(test)[:,4:]\n",
        "\n",
        "y_inverse = np.array(posttraimodel)[:,:4]\n",
        "\n",
        "y_test = np.array(test)[:,:4]\n",
        "print(y_inverse.shape, x_inverse.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4050, 124) (450, 124)\n",
            "(4050, 4) (4050, 120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arETTfa9F8EV",
        "outputId": "87ff3843-3966-4560-be78-a2f610dbee3c"
      },
      "source": [
        "\n",
        "\n",
        "#x_train_all, x_test, y_train_all, y_test = model_selection.train_test_split(x_inverse, y_inverse, test_size = 0.1)\n",
        "x_train_inv, x_val_inv, y_train_inv, y_val_inv = model_selection.train_test_split(x_inverse, y_inverse, test_size = 0.1)\n",
        "in_dim = x_train_inv.shape[1]\n",
        "out_dim = y_train_inv.shape[1]\n",
        "\n",
        "print(in_dim,\",\",out_dim)\n",
        "\n",
        "X_train = torch.from_numpy(x_train_inv).float()\n",
        "y_train = torch.squeeze(torch.from_numpy(y_train_inv).float())\n",
        "X_val = torch.from_numpy(x_val_inv).float()\n",
        "y_val = torch.squeeze(torch.from_numpy(y_val_inv).float())\n",
        "X_test = torch.from_numpy(x_test).float()\n",
        "y_test = torch.squeeze(torch.from_numpy(y_test).float())\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "# Hyperparameters for our network\n",
        "input_size = in_dim\n",
        "# Hyperparameters for our network\n",
        "hidden_sizes = [90,180,450, 600,750,500,300,120,60]#[90,180,450, 600,750,500,300,120,60]#[180,450, 600,250,150]#\n",
        "output_size = out_dim\n",
        "# Build a feed-forward network\n",
        "\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.SiLU(),\n",
        "                      nn.BatchNorm1d(hidden_sizes[0]),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.Tanh(),\n",
        "                      nn.BatchNorm1d(hidden_sizes[1]),\n",
        "                      nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
        "                      nn.SiLU(),\n",
        "                      nn.BatchNorm1d(hidden_sizes[2]),\n",
        "                      nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n",
        "                      nn.Tanh(),\n",
        "                      nn.BatchNorm1d(hidden_sizes[3]),\n",
        "                      nn.Linear(hidden_sizes[3], hidden_sizes[4]),\n",
        "                      nn.SiLU(),\n",
        "                      nn.BatchNorm1d(hidden_sizes[4]),\n",
        "                      nn.Linear(hidden_sizes[4], hidden_sizes[5]),\n",
        "                      nn.Tanh(),\n",
        "                      nn.BatchNorm1d(hidden_sizes[5]),\n",
        "                      nn.Linear(hidden_sizes[5], hidden_sizes[6]),\n",
        "                      nn.SiLU(),\n",
        "                      nn.BatchNorm1d(hidden_sizes[6]),\n",
        "                      nn.Linear(hidden_sizes[6], hidden_sizes[7]),\n",
        "                      nn.Tanh(),\n",
        "                      nn.BatchNorm1d(hidden_sizes[7]),\n",
        "                      nn.Linear(hidden_sizes[7], hidden_sizes[8]),\n",
        "                      nn.SiLU(),\n",
        "                      nn.BatchNorm1d(hidden_sizes[8]),\n",
        "                      nn.Linear(hidden_sizes[8], output_size),\n",
        "                      nn.Sigmoid())\n",
        "\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120 , 4\n",
            "torch.Size([3645, 120]) torch.Size([3645, 4])\n",
            "torch.Size([405, 120]) torch.Size([405, 4])\n",
            "Sequential(\n",
            "  (0): Linear(in_features=120, out_features=90, bias=True)\n",
            "  (1): SiLU()\n",
            "  (2): BatchNorm1d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Linear(in_features=90, out_features=180, bias=True)\n",
            "  (4): Tanh()\n",
            "  (5): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): Linear(in_features=180, out_features=450, bias=True)\n",
            "  (7): SiLU()\n",
            "  (8): BatchNorm1d(450, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): Linear(in_features=450, out_features=600, bias=True)\n",
            "  (10): Tanh()\n",
            "  (11): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (12): Linear(in_features=600, out_features=750, bias=True)\n",
            "  (13): SiLU()\n",
            "  (14): BatchNorm1d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): Linear(in_features=750, out_features=500, bias=True)\n",
            "  (16): Tanh()\n",
            "  (17): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (18): Linear(in_features=500, out_features=300, bias=True)\n",
            "  (19): SiLU()\n",
            "  (20): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (21): Linear(in_features=300, out_features=120, bias=True)\n",
            "  (22): Tanh()\n",
            "  (23): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (24): Linear(in_features=120, out_features=60, bias=True)\n",
            "  (25): SiLU()\n",
            "  (26): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (27): Linear(in_features=60, out_features=4, bias=True)\n",
            "  (28): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2Dv_p14mc4K",
        "outputId": "7f3a29e0-eeb8-4bad-8616-6da6bd237cbf"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=120, out_features=90, bias=True)\n",
              "  (1): SiLU()\n",
              "  (2): BatchNorm1d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (3): Linear(in_features=90, out_features=180, bias=True)\n",
              "  (4): Tanh()\n",
              "  (5): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (6): Linear(in_features=180, out_features=450, bias=True)\n",
              "  (7): SiLU()\n",
              "  (8): BatchNorm1d(450, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (9): Linear(in_features=450, out_features=600, bias=True)\n",
              "  (10): Tanh()\n",
              "  (11): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (12): Linear(in_features=600, out_features=750, bias=True)\n",
              "  (13): SiLU()\n",
              "  (14): BatchNorm1d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (15): Linear(in_features=750, out_features=500, bias=True)\n",
              "  (16): Tanh()\n",
              "  (17): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (18): Linear(in_features=500, out_features=300, bias=True)\n",
              "  (19): SiLU()\n",
              "  (20): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (21): Linear(in_features=300, out_features=120, bias=True)\n",
              "  (22): Tanh()\n",
              "  (23): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (24): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (25): SiLU()\n",
              "  (26): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (27): Linear(in_features=60, out_features=4, bias=True)\n",
              "  (28): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acHpBDlMhG27"
      },
      "source": [
        "total = pd.read_excel('/content/drive/My Drive/Files/TE/TE_500_700nm_all_design.xlsx')\n",
        "\n",
        "\n",
        "\n",
        "total[\"gap\"] = total[\"p\"] - 2*total[\"w\"]\n",
        "total[\"t\"] = total[\"t1\"] + total[\"t2\"]\n",
        "\n",
        "min_real = min(total[\"Re(r)\"])\n",
        "max_real = max(total[\"Re(r)\"])\n",
        "\n",
        "min_img = min(total[\"Img(r)\"])\n",
        "max_img = max(total[\"Img(r)\"])\n",
        "\n",
        "min_abs = min(total[\"A\"])\n",
        "max_abs = max(total[\"A\"])\n",
        "\n",
        "min_t1 = min(total[\"t1\"]) + 1j*(0)\n",
        "max_t1 = max(total[\"t1\"]) + 1j*(0)\n",
        "\n",
        "min_t2 = min(total[\"t2\"]) + 1j*(0)\n",
        "max_t2 = max(total[\"t2\"]) + 1j*(0)\n",
        "\n",
        "min_t = min(total[\"t\"]) + 1j*(0)\n",
        "max_t = max(total[\"t\"]) + 1j*(0)\n",
        "\n",
        "max_w = max(total[\"w\"]) + 1j*(0)\n",
        "max_p = max(total[\"p\"]) + 1j*(0)\n",
        "\n",
        "min_w = min(total[\"w\"]) + 1j*(0)\n",
        "min_p = min(total[\"p\"]) + 1j*(0)\n",
        "\n",
        "max_gap = max(total[\"gap\"]) + 1j*(0)\n",
        "min_gap = min(total[\"gap\"]) + 1j*(0)\n",
        "\n",
        "\n",
        "ref = pd.read_excel('/content/drive/My Drive/Files/TE/TE wvl and eps-40.xlsx')\n",
        "ref = np.array(ref)\n",
        "\n",
        "max_eps_real = max(ref[:,1])\n",
        "min_eps_real = min(ref[:,1])\n",
        "\n",
        "max_eps_img = max(ref[:,2])\n",
        "min_eps_img = min(ref[:,2])\n",
        "wvl_unshuffled = np.array(pd.read_excel('/content/drive/My Drive/Files/TE/TE wvl and eps-40.xlsx'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXi8bt9CGCHD"
      },
      "source": [
        "X_train, y_train, X_val, y_val, X_test, y_test = X_train.to(device), y_train.to(device), X_val.to(device), y_val.to(device), X_test.to(device), \\\n",
        "y_test.to(device)\n",
        "\n",
        "output = model(X_train)\n",
        "criterion = nn.L1Loss()#nn.MSELoss() #nn.BCELoss()\n",
        "#optimizer = torch.optim.AdamW(model.parameters(),lr=0.009)#,weight_decay=  0.00001)#0.001\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0015)#,weight_decay=  0.00001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.9,patience=10,min_lr=1e-06, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn4xfZfmSRch"
      },
      "source": [
        "wvl_list = np.array(pd.read_excel('/content/drive/My Drive/Files/TE/TE wvl and eps-40.xlsx'))\n",
        "wvl_list =  torch.from_numpy(wvl_list).float()\n",
        "\n",
        "wvl_num = len(wvl_list)\n",
        "\n",
        "\n",
        "def make_long_table(ytrue,ypred,X):#X=response, y = design\n",
        "\n",
        "  design_temp_true = torch.repeat_interleave(ytrue, 40, dim=0)#\n",
        "  design_temp_pred = torch.repeat_interleave(ypred,40, dim=0)#repeat the entire block\n",
        "\n",
        "\n",
        "  wvl_temp = torch.t(torch.tile(wvl_list[:,0],(1,len(ytrue))))\n",
        "  # print(\"each wavelength\",wvl_temp)\n",
        "  eps_real_temp = torch.t(torch.tile(wvl_list[:,1],(1,len(ytrue))))#not standardised\n",
        "  eps_imag_temp = torch.t(torch.tile(wvl_list[:,2],(1,len(ytrue))))#not standardised\n",
        "\n",
        "  abs_temp = X[:,:40]\n",
        "  # print(\"list of abs\",abs_temp)\n",
        "  imag_temp = X[:,40:80]\n",
        "  real_temp = X[:,80:]\n",
        "\n",
        "\n",
        "  abs_temp = torch.reshape(torch.reshape(abs_temp,(-1,)),(-1,1))\n",
        "  # print(\"abs corresponding to each wavelength\",abs_temp)\n",
        "  imag_temp = torch.reshape(torch.reshape(imag_temp,(-1,)),(-1,1))\n",
        "  real_temp = torch.reshape(torch.reshape(real_temp,(-1,)),(-1,1))\n",
        "\n",
        "  #print(wvl_temp.shape)\n",
        "\n",
        "  response_tbl = torch.hstack((real_temp,imag_temp,abs_temp,wvl_temp.to(device),eps_real_temp.to(device),eps_imag_temp.to(device)))\n",
        "\n",
        "  return design_temp_true.to(device),design_temp_pred.to(device),response_tbl\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(train_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhpMDteb1A-2"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36-3R7xgscPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4218f9-546a-45e8-f20d-33a48557854b"
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "def round_tensor(t, decimal_places=7):\n",
        "  return round(t.item(), decimal_places)\n",
        "\n",
        "#max_p = max(posttraimodel[\"p\"])\n",
        "\n",
        "wl_ratio_max = 35\n",
        "def my_loss(pred, true,inp):\n",
        "  wvl_mu = inp[:,3]\n",
        "  wvl = wvl_mu*1000\n",
        "\n",
        "  n_s = 1.55+0.01j\n",
        "  n_air =1\n",
        "\n",
        "  eps_au_real = inp[:,4]\n",
        "  eps_au_img = inp[:,5]\n",
        "\n",
        "  eps_au = torch.complex(eps_au_real,eps_au_img)\n",
        "  n_au = eps_au**0.5\n",
        "\n",
        "  n_sq = (n_au**2-n_air**2)\n",
        "\n",
        "\n",
        "\n",
        "  t2_p = pred[:,1]*(max_t2- min_t2) +min_t2\n",
        "  t_p = pred[:,3]*(max_t-  min_t) +min_t\n",
        "  t1_p = t_p-t2_p\n",
        "  t2_p_nm = t2_p*1000\n",
        "  t1_p_nm = t1_p*1000\n",
        "  p_p = pred[:,0]*(max_p - min_p) +min_p\n",
        "  gapp_p = pred[:,2]*(max_gap-min_gap) + min_gap\n",
        "\n",
        "  w_p = (p_p-gapp_p)/2\n",
        "\n",
        "  gap_p = p_p - w_p\n",
        "\n",
        "  a_data = inp[:,2]\n",
        "  real_data = inp[:,0]\n",
        "  imag_data = inp[:,1]\n",
        "\n",
        "  gap_ratio = torch.div(gap_p, p_p)#diff works\n",
        "  w_ratio = torch.div(w_p, p_p)\n",
        "\n",
        "  one = torch.div(w_p, w_p)\n",
        "  first_term = (w_ratio*(n_au**2))+((gap_ratio)*(n_air**2))\n",
        "  last_term = torch.div(n_sq,first_term)\n",
        "  period_wl = torch.div(p_p,wvl_mu)\n",
        "\n",
        "\n",
        "  arith_mean = (first_term)*(one+((first_term)*((w_ratio*w_ratio)*(gap_ratio*gap_ratio)*(period_wl*period_wl))\\\n",
        "                                  *(last_term*last_term)))\n",
        "\n",
        "  e_real = arith_mean.real\n",
        "  e_imag = arith_mean.imag\n",
        "\n",
        "  n_hom = arith_mean**0.5\n",
        "\n",
        "\n",
        "  phi_h = (2*pi*n_hom*t1_p_nm)/wvl\n",
        "  phi_s = (2*pi*n_s*t2_p_nm)/wvl\n",
        "\n",
        "\n",
        "\n",
        "  e_phi_h1 = torch.cos(phi_h) - 1j * torch.sin(phi_h) #torch.exp(phi_h*(-1j))\n",
        "  e_phi_s1 = torch.cos(phi_s) - 1j * torch.sin(phi_s) #torch.exp(phi_s*(-1j))\n",
        "\n",
        "\n",
        "\n",
        "  e_phi_h2 = torch.cos(phi_h) + 1j * torch.sin(phi_h)\n",
        "  e_phi_s2 = torch.cos(phi_s) + 1j * torch.sin(phi_s)\n",
        "\n",
        "  r_h = torch.div(n_hom-(1+0j), n_hom+(1+0j))*-1\n",
        "\n",
        "  r_s = torch.div(n_hom-(1.55+0.01j), n_hom+(1.55+0.01j))\n",
        "  r_au = torch.div(n_au-n_s, n_au+n_s)*-1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  T11 = e_phi_s1*(e_phi_h1+(r_h*r_s)*e_phi_h2)+ r_au*e_phi_s2*(r_s*e_phi_h1+r_h*e_phi_h2)\n",
        "  T21 = e_phi_s1*((r_h*e_phi_h1)+(r_s*e_phi_h2))+ r_au*e_phi_s2*((r_h*r_s)*e_phi_h1+e_phi_h2)\n",
        "\n",
        "  r_coeff = torch.div(T21, T11)\n",
        "\n",
        "  r_coeff = torch.div(T21, T11)\n",
        "  r = r_coeff.abs()\n",
        "  real = r_coeff.real\n",
        "  imag = r_coeff.imag\n",
        "  a = 1-r**2\n",
        "\n",
        "  a_scaled = (a-min_abs)/(max_abs-min_abs)\n",
        "  real_scaled = (real-min_real)/(max_real-min_real)\n",
        "  imag_scaled = (imag-min_img)/(max_img-min_img)\n",
        "\n",
        "\n",
        "  calc_weight_phy = torch.div(wvl_mu,p_p.real)\n",
        "\n",
        "  mask = calc_weight_phy < 3\n",
        "\n",
        "\n",
        "  weight_phy = (calc_weight_phy/wl_ratio_max)**2\n",
        "  weight_phy[mask]=0\n",
        "  weight_data = (1-weight_phy)\n",
        "\n",
        "\n",
        "  loss_abs = weight_phy*torch.abs((a_scaled-a_data))\n",
        "  loss_real = weight_phy*torch.abs((real_scaled-real_data))\n",
        "  loss_imag = weight_phy*torch.abs((imag_scaled-imag_data))\n",
        "\n",
        "\n",
        "  loss_data = torch.abs(pred - true)\n",
        "  mean_loss_data = (1+weight_data)*torch.mean(loss_data, 1)\n",
        "\n",
        "\n",
        "  loss_phy = (loss_abs) + (loss_real) + (loss_imag)\n",
        "\n",
        "\n",
        "  loss = 0.5*loss_phy + (mean_loss_data)\n",
        "\n",
        "\n",
        "\n",
        "  return torch.mean(loss)#,weight_data\n",
        "\n",
        "train_loss_list =[]\n",
        "val_loss_list =[]\n",
        "\n",
        "total_epochs = 5000 #3000\n",
        "for epoch in range(total_epochs):\n",
        "\n",
        "  y_pred = model(X_train)#(X_train_batch)\n",
        "  #print(y_pred)\n",
        "  y_pred = torch.squeeze(y_pred)\n",
        "\n",
        "  X_recon = forward_model(y_pred)\n",
        "\n",
        "  design_tbl_true,design_tbl_pred,rspns_tbl = make_long_table(y_train,y_pred,X_train)\n",
        "  phyloss = my_loss(design_tbl_pred, design_tbl_true,rspns_tbl)\n",
        "  reconloss = criterion(X_recon,X_train)\n",
        "  designloss = criterion(y_pred,y_train)\n",
        "\n",
        "  train_loss = phyloss  + reconloss\n",
        "\n",
        "  train_loss_list.append(round_tensor(train_loss))\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  train_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  #print(train_loss)\n",
        "  if epoch % 50 == 0:\n",
        "    #train_acc = calculate_accuracy(y_train, y_pred)\n",
        "    y_val_pred = model(X_val)\n",
        "    y_val_pred = torch.squeeze(y_val_pred)\n",
        "    test_loss = criterion(y_val_pred,y_val)\n",
        "    val_loss_list.append(round_tensor(test_loss))\n",
        "\n",
        "    print(\"epoch\",epoch,\"train loss\",round_tensor(designloss),\"phy loss\",round_tensor(phyloss), \"val loss\",round_tensor(test_loss),\"test loss\",round_tensor(criterion(model(X_test),y_test)))\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train loss 0.2519158 phy loss 0.5039274 val loss 0.2336054 test loss 0.230305\n",
            "epoch 50 train loss 0.1026659 phy loss 0.2053314 val loss 0.1010288 test loss 0.1006569\n",
            "epoch 100 train loss 0.0874196 phy loss 0.1748481 val loss 0.0889569 test loss 0.0904265\n",
            "epoch 150 train loss 0.056922 phy loss 0.113833 val loss 0.0634936 test loss 0.0662336\n",
            "epoch 200 train loss 0.0525534 phy loss 0.1052018 val loss 0.0586056 test loss 0.0609354\n",
            "epoch 250 train loss 0.0408279 phy loss 0.0816752 val loss 0.0529628 test loss 0.0534458\n",
            "epoch 300 train loss 0.0375053 phy loss 0.0750238 val loss 0.0509535 test loss 0.0461054\n",
            "epoch 350 train loss 0.0321763 phy loss 0.0643515 val loss 0.0444405 test loss 0.044522\n",
            "epoch 400 train loss 0.03121 phy loss 0.0623795 val loss 0.0463022 test loss 0.0413449\n",
            "epoch 450 train loss 0.0273109 phy loss 0.0546533 val loss 0.0424364 test loss 0.0448499\n",
            "epoch 500 train loss 0.0268731 phy loss 0.0537735 val loss 0.042675 test loss 0.0427181\n",
            "epoch 550 train loss 0.0230105 phy loss 0.0460385 val loss 0.0399924 test loss 0.0378509\n",
            "epoch 600 train loss 0.0190976 phy loss 0.0382523 val loss 0.0392978 test loss 0.0352127\n",
            "epoch 650 train loss 0.0213051 phy loss 0.0425771 val loss 0.0391702 test loss 0.0380902\n",
            "epoch 700 train loss 0.0172441 phy loss 0.0344963 val loss 0.0360902 test loss 0.0354933\n",
            "epoch 750 train loss 0.0155583 phy loss 0.0311245 val loss 0.0320752 test loss 0.0345269\n",
            "epoch 800 train loss 0.0157236 phy loss 0.0314655 val loss 0.0314567 test loss 0.0346413\n",
            "epoch 850 train loss 0.0140766 phy loss 0.0281556 val loss 0.0358787 test loss 0.0309207\n",
            "epoch 900 train loss 0.0139937 phy loss 0.0279929 val loss 0.0339234 test loss 0.0329617\n",
            "epoch 950 train loss 0.0135475 phy loss 0.0271338 val loss 0.0333588 test loss 0.0332182\n",
            "epoch 1000 train loss 0.0126534 phy loss 0.0252992 val loss 0.0368483 test loss 0.0298039\n",
            "epoch 1050 train loss 0.0118831 phy loss 0.0237819 val loss 0.0353131 test loss 0.0302516\n",
            "epoch 1100 train loss 0.010785 phy loss 0.02161 val loss 0.0334382 test loss 0.0344624\n",
            "epoch 1150 train loss 0.0098683 phy loss 0.0197471 val loss 0.0330555 test loss 0.0281157\n",
            "epoch 1200 train loss 0.0112054 phy loss 0.0224388 val loss 0.035132 test loss 0.0313544\n",
            "epoch 1250 train loss 0.0089092 phy loss 0.0178666 val loss 0.0306914 test loss 0.0282594\n",
            "epoch 1300 train loss 0.0087486 phy loss 0.0175299 val loss 0.0303647 test loss 0.0296273\n",
            "epoch 1350 train loss 0.0090069 phy loss 0.0180216 val loss 0.0309736 test loss 0.0291042\n",
            "epoch 1400 train loss 0.0078102 phy loss 0.0156597 val loss 0.0299331 test loss 0.0300972\n",
            "epoch 1450 train loss 0.0086746 phy loss 0.0173768 val loss 0.0295589 test loss 0.0286041\n",
            "epoch 1500 train loss 0.0084809 phy loss 0.0170084 val loss 0.0289898 test loss 0.0282707\n",
            "epoch 1550 train loss 0.0082466 phy loss 0.0165062 val loss 0.0306943 test loss 0.0293915\n",
            "epoch 1600 train loss 0.0078275 phy loss 0.0156911 val loss 0.0299083 test loss 0.0273293\n",
            "epoch 1650 train loss 0.0086077 phy loss 0.0172315 val loss 0.0298441 test loss 0.0287446\n",
            "epoch 1700 train loss 0.0074456 phy loss 0.0149061 val loss 0.0289307 test loss 0.0284452\n",
            "epoch 1750 train loss 0.0077655 phy loss 0.0155635 val loss 0.0277543 test loss 0.0286445\n",
            "epoch 1800 train loss 0.0074448 phy loss 0.0149378 val loss 0.028702 test loss 0.0294075\n",
            "epoch 1850 train loss 0.0071251 phy loss 0.014299 val loss 0.0294728 test loss 0.0281227\n",
            "epoch 1900 train loss 0.0072782 phy loss 0.0145798 val loss 0.028316 test loss 0.0284896\n",
            "epoch 1950 train loss 0.0070386 phy loss 0.0140967 val loss 0.0294491 test loss 0.0283768\n",
            "epoch 2000 train loss 0.006757 phy loss 0.0135402 val loss 0.0292465 test loss 0.0278978\n",
            "epoch 2050 train loss 0.0074866 phy loss 0.0150014 val loss 0.0284506 test loss 0.0293418\n",
            "epoch 2100 train loss 0.0061568 phy loss 0.0123498 val loss 0.0279414 test loss 0.0264238\n",
            "epoch 2150 train loss 0.0056504 phy loss 0.0113352 val loss 0.0280606 test loss 0.0280187\n",
            "epoch 2200 train loss 0.0064519 phy loss 0.0129361 val loss 0.027509 test loss 0.0282117\n",
            "epoch 2250 train loss 0.0064302 phy loss 0.0128878 val loss 0.028071 test loss 0.0296731\n",
            "epoch 2300 train loss 0.0064466 phy loss 0.0129238 val loss 0.0289375 test loss 0.0289307\n",
            "epoch 2350 train loss 0.0065955 phy loss 0.0132295 val loss 0.028587 test loss 0.026985\n",
            "epoch 2400 train loss 0.0064328 phy loss 0.0129272 val loss 0.0291733 test loss 0.028525\n",
            "epoch 2450 train loss 0.0060315 phy loss 0.0121393 val loss 0.0282591 test loss 0.0293346\n",
            "epoch 2500 train loss 0.0058815 phy loss 0.0118013 val loss 0.0281763 test loss 0.0283857\n",
            "epoch 2550 train loss 0.0058041 phy loss 0.0116426 val loss 0.0291659 test loss 0.0281167\n",
            "epoch 2600 train loss 0.0069936 phy loss 0.0140709 val loss 0.0274444 test loss 0.0276487\n",
            "epoch 2650 train loss 0.0052776 phy loss 0.0105886 val loss 0.0287476 test loss 0.0280493\n",
            "epoch 2700 train loss 0.0056094 phy loss 0.0112689 val loss 0.0274718 test loss 0.027767\n",
            "epoch 2750 train loss 0.0054804 phy loss 0.0109953 val loss 0.0278832 test loss 0.0273941\n",
            "epoch 2800 train loss 0.005543 phy loss 0.0111179 val loss 0.0281139 test loss 0.0268982\n",
            "epoch 2850 train loss 0.0054952 phy loss 0.0110363 val loss 0.0276307 test loss 0.0275779\n",
            "epoch 2900 train loss 0.0056699 phy loss 0.0113797 val loss 0.028175 test loss 0.0278956\n",
            "epoch 2950 train loss 0.0058118 phy loss 0.0116716 val loss 0.0293598 test loss 0.0276927\n",
            "epoch 3000 train loss 0.005411 phy loss 0.0108611 val loss 0.0270994 test loss 0.0285752\n",
            "epoch 3050 train loss 0.0051842 phy loss 0.0104094 val loss 0.0282792 test loss 0.0269207\n",
            "epoch 3100 train loss 0.0054603 phy loss 0.0109596 val loss 0.0274531 test loss 0.0276657\n",
            "epoch 3150 train loss 0.0053653 phy loss 0.0107673 val loss 0.0281804 test loss 0.0263552\n",
            "epoch 3200 train loss 0.0054463 phy loss 0.0109496 val loss 0.0284895 test loss 0.0275835\n",
            "epoch 3250 train loss 0.0048391 phy loss 0.0097319 val loss 0.0281441 test loss 0.0274632\n",
            "epoch 3300 train loss 0.005417 phy loss 0.0108793 val loss 0.0290863 test loss 0.0277608\n",
            "epoch 3350 train loss 0.0058182 phy loss 0.0116835 val loss 0.0275449 test loss 0.0287966\n",
            "epoch 3400 train loss 0.0047513 phy loss 0.0095526 val loss 0.0277058 test loss 0.027414\n",
            "epoch 3450 train loss 0.0050329 phy loss 0.0100993 val loss 0.0282663 test loss 0.0270097\n",
            "epoch 3500 train loss 0.0047947 phy loss 0.0096636 val loss 0.0279568 test loss 0.0268509\n",
            "epoch 3550 train loss 0.0047704 phy loss 0.0095783 val loss 0.0274453 test loss 0.0262706\n",
            "epoch 3600 train loss 0.0048241 phy loss 0.0096851 val loss 0.0284966 test loss 0.0265499\n",
            "epoch 3650 train loss 0.0046028 phy loss 0.0092626 val loss 0.0283927 test loss 0.0260896\n",
            "epoch 3700 train loss 0.0049634 phy loss 0.0099741 val loss 0.0281362 test loss 0.0268244\n",
            "epoch 3750 train loss 0.0052544 phy loss 0.0105693 val loss 0.0269826 test loss 0.027536\n",
            "epoch 3800 train loss 0.0044729 phy loss 0.0089918 val loss 0.0273761 test loss 0.0263161\n",
            "epoch 3850 train loss 0.0049002 phy loss 0.0098324 val loss 0.0272135 test loss 0.0264499\n",
            "epoch 3900 train loss 0.004661 phy loss 0.0093772 val loss 0.0276711 test loss 0.0262813\n",
            "epoch 3950 train loss 0.0050989 phy loss 0.0102271 val loss 0.0278006 test loss 0.0269557\n",
            "epoch 4000 train loss 0.0043017 phy loss 0.00865 val loss 0.0276603 test loss 0.0257486\n",
            "epoch 4050 train loss 0.0041814 phy loss 0.0084177 val loss 0.0277212 test loss 0.0262752\n",
            "epoch 4100 train loss 0.0042922 phy loss 0.008624 val loss 0.0277517 test loss 0.0270313\n",
            "epoch 4150 train loss 0.0042539 phy loss 0.0085673 val loss 0.0277722 test loss 0.0265208\n",
            "epoch 4200 train loss 0.0044772 phy loss 0.0090148 val loss 0.0269365 test loss 0.0253295\n",
            "epoch 4250 train loss 0.0045572 phy loss 0.0091674 val loss 0.027813 test loss 0.0274501\n",
            "epoch 4300 train loss 0.0044228 phy loss 0.0089079 val loss 0.0281649 test loss 0.0262403\n",
            "epoch 4350 train loss 0.00426 phy loss 0.0085736 val loss 0.027775 test loss 0.0260033\n",
            "epoch 4400 train loss 0.0046205 phy loss 0.0092808 val loss 0.0281024 test loss 0.0258452\n",
            "epoch 4450 train loss 0.0039593 phy loss 0.0079625 val loss 0.0278205 test loss 0.0268233\n",
            "epoch 4500 train loss 0.0039428 phy loss 0.0079307 val loss 0.0272123 test loss 0.025684\n",
            "epoch 4550 train loss 0.0103212 phy loss 0.0206624 val loss 0.0311403 test loss 0.031924\n",
            "epoch 4600 train loss 0.0046501 phy loss 0.0093392 val loss 0.0272454 test loss 0.0256443\n",
            "epoch 4650 train loss 0.0042942 phy loss 0.0086443 val loss 0.0263597 test loss 0.0264663\n",
            "epoch 4700 train loss 0.0042 phy loss 0.0084506 val loss 0.0263166 test loss 0.0255574\n",
            "epoch 4750 train loss 0.0038105 phy loss 0.0076645 val loss 0.0269234 test loss 0.0265229\n",
            "epoch 4800 train loss 0.0041361 phy loss 0.0083132 val loss 0.0272862 test loss 0.0257693\n",
            "epoch 4850 train loss 0.0038761 phy loss 0.007798 val loss 0.0275691 test loss 0.0261991\n",
            "epoch 4900 train loss 0.0039704 phy loss 0.0080121 val loss 0.0273841 test loss 0.0259028\n",
            "epoch 4950 train loss 0.0037738 phy loss 0.0076016 val loss 0.0275716 test loss 0.02655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHAYn8o_9Y1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "0e4d223d-cc53-41c7-9259-4f21255e1fe9"
      },
      "source": [
        "plt.plot(range(total_epochs),train_loss_list, label = \"Train loss\")\n",
        "plt.plot(range(0,total_epochs,50),val_loss_list, label = \"Val loss\")\n",
        "\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"absolute error\")\n",
        "plt.legend(loc=1, prop={'size': 9})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f654ce79fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrjbanGLGSC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d3c0e89e-e8a7-446c-ece5-f79c39365ca9"
      },
      "source": [
        "ytest = model(X_test)\n",
        "\n",
        "\n",
        "\n",
        "total_x_test = forward_model(ytest)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "numpy_x_pred = total_x_test.cpu().detach().numpy()\n",
        "response_pred=pd.DataFrame(numpy_x_pred)\n",
        "\n",
        "numpy_y_pred = ytest.cpu().detach().numpy()\n",
        "design_pred=pd.DataFrame(numpy_y_pred)\n",
        "\n",
        "numpy_y_actual = y_test.cpu().detach().numpy()\n",
        "design_actual=pd.DataFrame(numpy_y_actual)\n",
        "\n",
        "numpy_x_actual = X_test.cpu().detach().numpy()\n",
        "#numpy_x_actual = X_test.cpu().detach().numpy()\n",
        "response_actual = pd.DataFrame(numpy_x_actual)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nnumpy_y_pred = ytest.detach().numpy()\\nresponse_pred=pd.DataFrame(numpy_y_pred)\\n\\nnumpy_y_actual = y_test.detach().numpy()\\nresponse_actual=pd.DataFrame(numpy_y_actual)\\n\\nnumpy_x_actual = X_test.detach().numpy()\\ndesign_actual = pd.DataFrame(numpy_x_actual)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_oK8kkJhVlc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk0VOjz0GYTO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04CKM6nFG3Qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ab4417-d656-47e0-d3b5-8204edaee727"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "print(\"p MAE:\", mean_absolute_error(design_pred[design_pred.columns[0]], design_actual[design_actual.columns[0]]))\n",
        "print(\"t2 MAE:\", mean_absolute_error(design_pred[design_pred.columns[1]], design_actual[design_actual.columns[1]]))\n",
        "print(\"gap MAE:\", mean_absolute_error(design_pred[design_pred.columns[2]], design_actual[design_actual.columns[2]]))\n",
        "print(\"t MAE:\", mean_absolute_error(design_pred[design_pred.columns[3]], design_actual[design_actual.columns[3]]))\n",
        "print(\"Design MAE:\", mean_absolute_error(design_pred, design_actual))\n",
        "#\"\"\"\n",
        "print(\"Abs MAE:\", mean_absolute_error(response_pred[response_pred.columns[:40]], response_actual[response_actual.columns[:40]]))\n",
        "print(\"Imag MAE:\", mean_absolute_error(response_pred[response_pred.columns[40:80]], response_actual[response_actual.columns[40:80]]))\n",
        "print(\"Real MAE:\", mean_absolute_error(response_pred[response_pred.columns[80:]], response_actual[response_actual.columns[80:]]))\n",
        "print(\"Real ref MAE:\", mean_absolute_error(response_pred, response_actual))\n",
        "\n",
        "#\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p MAE: 0.038371015\n",
            "t2 MAE: 0.020497594\n",
            "gap MAE: 0.027614508\n",
            "t MAE: 0.017914636\n",
            "Design MAE: 0.026099443\n",
            "Abs MAE: 0.037854437\n",
            "Imag MAE: 0.0355385\n",
            "Real MAE: 0.029904444\n",
            "Real ref MAE: 0.03443246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVr5CqQfB5Xv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8fo-s_gjEU-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "7a41d9ef-26df-4e0d-fa71-09239c57ebb0"
      },
      "source": [
        "\"\"\"\n",
        "Real ref MAE: 0.014028428\n",
        "Imag ref MAE: 0.013966705\n",
        "Absorption MAE: 0.020597955\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nReal ref MAE: 0.014028428\\nImag ref MAE: 0.013966705\\nAbsorption MAE: 0.020597955\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwZg7LIQS6uw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EptkKaOZjqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5816d3ce-dacf-47c9-cd8f-c2b18f232e6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}